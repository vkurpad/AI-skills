{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 41.168s.\n",
      "Processing 500 documents\n",
      "done in 81.580s.\n",
      "Processing 1000 documents\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlockBlobService\n",
    "from time import time\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "STORAGEACCOUNTNAME= 'knowstoredemo'\n",
    "STORAGEACCOUNTKEY= ''\n",
    "LOCALFILENAME= 'temp.json'\n",
    "CONTAINERNAME= 'hotelreviews'\n",
    "cols_to_del  = ['metadata_storage_content_type', 'metadata_storage_size', 'metadata_storage_path', 'metadata_storage_content_md5', \n",
    "             'metadata_storage_last_modified', 'latitude','longitude', 'reviews_date','reviews_dateAdded', \n",
    "             'reviews_username', 'metadata_storage_name']\n",
    "BLOBNAME= ''\n",
    "big_df = pd.DataFrame()\n",
    "#download from blob\n",
    "count = 0\n",
    "blob_service=BlockBlobService(account_name=STORAGEACCOUNTNAME,account_key=STORAGEACCOUNTKEY)\n",
    "blob_names = blob_service.list_blobs(CONTAINERNAME)\n",
    "\n",
    "t0 = time()\n",
    "for blob in blob_names:\n",
    "    blob_service.get_blob_to_path(CONTAINERNAME,blob.name,LOCALFILENAME)\n",
    "    df = pd.read_json(LOCALFILENAME)\n",
    "    \n",
    "    \n",
    "    for col in cols_to_del:\n",
    "        if col in df.columns:\n",
    "            del df[col]\n",
    "    try:\n",
    "        \n",
    "        pages = json_normalize(df['pages'])\n",
    "        df['LanguageCode' ] = pages['LanguageCode']\n",
    "        df['SentimentScore'] = pages ['SentimentScore']\n",
    "        #df.drop(['metadata_storage_content_type', 'metadata_storage_size', 'metadata_storage_path', 'metadata_storage_content_md5', \n",
    "        #         'metadata_storage_last_modified', 'latitude','longitude', 'reviews_date','reviews_dateAdded', \n",
    "        #         'reviews_username', 'metadata_storage_name'],axis=1, inplace=True, sort=False)\n",
    "\n",
    "        #df1 = df[['address', 'categories', 'city', 'country', 'postalCode', 'province', 'name', 'reviews_rating', 'reviews_text', 'reviews_title', 'pages', 'AzureSearch_DocumentKey']]\n",
    "        frames = [big_df, df]\n",
    "        big_df= pd.concat(frames, sort=False)\n",
    "        count = count+ 1\n",
    "        if count % 500 == 0:\n",
    "            print(\"done in %0.3fs.\" % (time() - t0))\n",
    "            print(f'Processing {count} documents' )\n",
    "            \n",
    "    except:\n",
    "        print(\"Exception\")\n",
    "        #print(AzureSearch_DocumentKey)\n",
    "        print(df['pages'])\n",
    "        \n",
    "print(f'Processed {count} documents' )\n",
    "print(big_df.columns)\n",
    "print(big_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_features = 5000\n",
    "n_components = 10\n",
    "n_top_words = 20\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = big_df.loc[big_df['LanguageCode'] == \"en\"]\n",
    "x.head()\n",
    "data = x['reviews_text'].values.tolist()\n",
    "n_samples = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 0.047s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data)\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 0.065s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data)\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=500 and n_features=5000...\n",
      "done in 0.127s.\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "\n",
    "#          alpha=.1, l1_ratio=.5).fit(n_tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: room clean comfortable stayed bed breakfast did night beds check desk quiet day shower water bathroom floor coffee like old\n",
      "Topic #1: nice breakfast close free experience staff freeway facility amenities pretty pleasant pet wish smoke left eggs definitely large facilities bit\n",
      "Topic #2: hotel location perfect close florence best sure walk train recommend spacious convenient highly ville visit la station really venue shopping\n",
      "Topic #3: great place location free breakfast staying parking lots service downtown bike inside stay time people slow bathrooms huge kinda check\n",
      "Topic #4: friendly staff stay helpful clean comfortable make enjoyed easy recommend super breakfast want place located extremely highly distance attentive beds\n",
      "Topic #5: excellent staff beds breakfast wedding comfortable location quiet service lovely buffet impeccable accommodating free hard guests levels sight rate party\n",
      "Topic #6: beautiful rooms classic courteous helpful place mary venue area city cute manager decent ideal fancy large level enjoyed food loved\n",
      "Topic #7: wonderful experience location loved wedding come want future wifi glad inn visits stay number decor club bus sure mt gardner\n",
      "Topic #8: good breakfast employees rates 374 really right eggs price clean experience event paper buffet free food area service pleasant pretty\n",
      "Topic #9: pool area spa just enjoyable isn fyi locked enjoy heated overnight stay temperature hot perfect clean hours fun enjoyed grandkids\n",
      "\n",
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=500 and n_features=5000...\n",
      "done in 0.291s.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=8000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: room hotel night did bed bathroom stayed clean nice desk didn old asked like quiet coffee check checked went stay\n",
      "Topic #1: nice breakfast friendly staff clean close helpful free lobby freeway eggs maintained access pretty la convenient amenities buffet easy large\n",
      "Topic #2: hotel location great staff perfect florence stay best recommend close located look park restaurants walking shopping enjoyed want city amazing\n",
      "Topic #3: great breakfast free place dirty internet people coffee hour bad good downtown morning cookies kind crappy don check bathrooms hot\n",
      "Topic #4: clean friendly stay helpful comfortable inn stayed gardner staff super place looking mt accommodations quick awful college enjoyed greg alison\n",
      "Topic #5: comfortable clean beds breakfast excellent staff good helpful friendly bed accommodating location desk service rooms parking best quality buffet pillows\n",
      "Topic #6: rooms hotel good just place beautiful fine clean like better choice city lobby kids hear pool decent new breakfast rates\n",
      "Topic #7: day staff night check service rooms wedding citizen told nights left decor guests called stayed couldn time venue said booked\n",
      "Topic #8: good breakfast wonderful day really slept definitely 10 experience walk stay easy close door right dinner got 374 check minute\n",
      "Topic #9: area pool hotel stay hot quite clean just breakfast early xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx disappointed check booked enjoy family enjoyed neighborhood website overnight\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=500 and n_features=5000...\n",
      "done in 59.969s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: disappointed locked website evening pool music enjoyable fyi spa area enjoy just isn terrific expedia 374 list live pizza said\n",
      "Topic #1: hotel room staff breakfast clean stay great nice friendly good comfortable rooms location stayed helpful night day area free like\n",
      "Topic #2: stay reservation rooms complimentary computer walking number prices did place travelers access day time fabulous absolutely awful data shortsince showing\n",
      "Topic #3: slept heated heart tunnels impeccable bike wonderful ending facility avoid ll seating gorgeous rates 22 save stepped overnight worse employees\n",
      "Topic #4: quite emails taking quickly better respond floor specifically thorough room definately smell xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx needed wedding online hear knowledgeable forgot way\n",
      "Topic #5: hotel park told night inn stay expedia 88 great enjoy methow neighborhood let motel charged state valet check businesswith united\n",
      "Topic #6: cleaning sweet people problem smell heated heart tunnels impeccable bike wonderful ending facility avoid ll seating gorgeous rates 22 save\n",
      "Topic #7: check toilet price paper com worst night laquinta came elevator didnt cleaned nasty soft terrible man needs checked dried woman\n",
      "Topic #8: room told nights year credit said internet manager drain second tub saw used gave hair lucky live smell roach spider\n",
      "Topic #9: room dirty inside stars eventually fell knoxville hotels old desk bathtub dusty nightly quiet did constant asleep stated com bell\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=800,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "#n_lda.fit(n_tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting batch of rows for Topic-0\n",
      "Inserting batch of rows for Topic-1\n",
      "Inserting batch of rows for Topic-2\n",
      "Inserting batch of rows for Topic-3\n",
      "Inserting batch of rows for Topic-4\n",
      "Inserting batch of rows for Topic-5\n",
      "Inserting batch of rows for Topic-6\n",
      "Inserting batch of rows for Topic-7\n",
      "Inserting batch of rows for Topic-8\n",
      "Inserting batch of rows for Topic-9\n"
     ]
    }
   ],
   "source": [
    "from azure.cosmosdb.table.tableservice import TableService\n",
    "from azure.cosmosdb.table.models import Entity\n",
    "from azure.cosmosdb.table.tablebatch import TableBatch\n",
    "\n",
    "table_service = TableService(account_name='knowstoredemo', account_key=STORAGEACCOUNTKEY)\n",
    "table_name = 'LDAResults'\n",
    "table_service.create_table(table_name)\n",
    "def save_top_words(model, feature_names, n_top_words, table_name):\n",
    "    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        batch = TableBatch()\n",
    "        part_key = \"Topic-%d\" % topic_idx\n",
    "        \n",
    "        for i in topic.argsort()[:-n_top_words - 1:-1]:\n",
    "            row_key = feature_names[i]\n",
    "            rec = {'PartitionKey': part_key, 'RowKey': row_key,\n",
    "           'Topic': part_key, 'Keyword': row_key}\n",
    "            batch.insert_entity(rec)\n",
    "        table_service.commit_batch('LDAResults', batch)\n",
    "        print(\"Inserting batch of rows for \" + part_key)\n",
    "\n",
    "save_top_words(lda, tf_feature_names, n_top_words, table_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-ai-skills",
   "language": "python",
   "name": "nlp-ai-skills"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
